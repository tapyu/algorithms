using FileIO, JLD2, Random, LinearAlgebra, Plots, LaTeXStrings
Œ£=sum

## load the data
ùêó, labels = FileIO.load("Datasets/Iris [uci]/iris.jld2", "ùêó", "ùêù") # ùêó ‚û° [attributes X instances]
# PS choose only one!!!
# uncomment ‚Üì if you want to train for all attributes
ùêó = [fill(-1, size(ùêó,2))'; ùêó] # add the -1 input (bias)
# uncomment ‚Üì if you want to train for petal length and width (to plot the decision surface)
# ùêó = [fill(-1, size(ùêó,2))'; ùêó[3:4,:]] # add the -1 input (bias)

## useful functions
function shuffle_dataset(ùêó, ùêù)
    shuffle_indices = Random.shuffle(1:size(ùêó,2))
    return ùêó[:, shuffle_indices], ùêù[shuffle_indices]
end

function train(ùêó, ùêù, ùê∞, is_training_accuracy=true)
    œÜ = u‚Çç‚Çô‚Çé -> u‚Çç‚Çô‚Çé>0 ? 1 : 0 # McCulloch and Pitts's activation function (step function)
    N‚Çë = 0 # number of errors ‚û° misclassifications
    for (ùê±‚Çç‚Çô‚Çé, d‚Çç‚Çô‚Çé) ‚àà zip(eachcol(ùêó), ùêù)
        Œº‚Çç‚Çô‚Çé = dot(ùê±‚Çç‚Çô‚Çé,ùê∞) # inner product
        y‚Çç‚Çô‚Çé = œÜ(Œº‚Çç‚Çô‚Çé) # for the training phase, you do not pass y‚Çç‚Çô‚Çé to a harder decisor (the McCulloch and Pitts's activation function) since you are in intended to classify y‚Çç‚Çô‚Çé. Rather, you are interested in updating ùê∞ (??? TODO)
        e‚Çç‚Çô‚Çé = d‚Çç‚Çô‚Çé - y‚Çç‚Çô‚Çé
        ùê∞ += Œ±*e‚Çç‚Çô‚Çé*ùê±‚Çç‚Çô‚Çé

        # this part is optional: only if it is interested in seeing the accuracy evolution of the training dataset throughout the epochs
        N‚Çë = e‚Çç‚Çô‚Çé==0 ? N‚Çë : N‚Çë+1
    end
    if is_training_accuracy
        accuracy = (length(ùêù)-N‚Çë)/length(ùêù) # accuracy for this epoch
        return ùê∞, accuracy
    else
        return ùê∞
    end
end

function test(ùêó, ùêù, ùê∞, is_confusion_matrix=false)
    œÜ = u‚Çç‚Çô‚Çé -> u‚Çç‚Çô‚Çé>0 ? 1 : 0 # McCulloch and Pitts's activation function (step function)
    ùê≤ = rand(length(ùêù)) # vector of predictions for confusion matrix
    N‚Çë = 0
    for (n, (ùê±‚Çç‚Çô‚Çé, d‚Çç‚Çô‚Çé)) ‚àà enumerate(zip(eachcol(ùêó), ùêù))
        Œº‚Çç‚Çô‚Çé = ùê±‚Çç‚Çô‚Çé‚ãÖùê∞ # inner product
        y‚Çç‚Çô‚Çé = œÜ(Œº‚Çç‚Çô‚Çé) # for the single-unit perceptron, y‚Çç‚Çô‚Çé ‚àà {0,1}. Therefore, it is not necessary to pass y‚Çç‚Çô‚Çé to a harder decisor since œÜ(‚ãÖ) already does this job
        ùê≤[n] = y‚Çç‚Çô‚Çé

        N‚Çë = y‚Çç‚Çô‚Çé==d‚Çç‚Çô‚Çé ? N‚Çë : N‚Çë+1
    end
    if !is_confusion_matrix
        accuracy = (length(ùêù)-N‚Çë)/length(ùêù)
        return accuracy # return the accuracy for this realization
    else
        return Int.(ùê≤) # return the errors over the instances to plot the confusion matrix
    end
end

## algorithm parameters hyperparameters
N·µ£ = 20 # number of realizations
N‚Çê = size(ùêó, 1) # =5 (including bias) number of Attributes, that is, input vector size at each intance. They mean: sepal length, sepal width, petal length, petal width
N = size(ùêó, 2) # =150 number of instances(samples)
N‚Çú·µ£‚Çô = 80 # % percentage of instances for the train dataset
N‚Çú‚Çõ‚Çú = 20 # % percentage of instances for the test dataset
N‚Çë = 100 # number of epochs
Œ± = 0.01 # learning step

## init
all_aÃÑcÃÑcÃÑ, all_œÉacc, all_ùê∞‚Çí‚Çö‚Çú = rand(3), rand(3), rand(N‚Çê,3)
for (i, desired_label) ‚àà enumerate(("setosa", "virginica", "versicolor"))
    local ùêù = labels.==desired_label # d‚Çç‚Çô‚Çé ‚àà {0,1}
    local acc‚Çú‚Çõ‚Çú = fill(NaN, N·µ£) # vector of accuracies for test dataset (to compute the final statistics)
    for n·µ£ ‚àà 1:N·µ£ # for each realization
        # initializing!
        acc‚Çú·µ£‚Çô = fill(NaN, N‚Çë) # vector of accuracies for train dataset (to see its evolution during training phase)
        global ùê∞ = ones(N‚Çê) # initialize a new McCulloch-Pitts neuron (a new set of parameters)
        global ùêó # ?

        # prepare the data!
        ùêó, ùêù = shuffle_dataset(ùêó, ùêù)
        # hould-out
        global ùêó‚Çú·µ£‚Çô = ùêó[:,1:(N*N‚Çú·µ£‚Çô)√∑100]
        global ùêù‚Çú·µ£‚Çô = ùêù[1:(N*N‚Çú·µ£‚Çô)√∑100]
        global ùêó‚Çú‚Çõ‚Çú = ùêó[:,length(ùêù‚Çú·µ£‚Çô)+1:end]
        global ùêù‚Çú‚Çõ‚Çú = ùêù[length(ùêù‚Çú·µ£‚Çô)+1:end]

        # train!
        for n‚Çë ‚àà 1:N‚Çë # for each epoch
            ùê∞, acc‚Çú·µ£‚Çô[n‚Çë] = train(ùêó‚Çú·µ£‚Çô, ùêù‚Çú·µ£‚Çô, ùê∞)
            ùêó‚Çú·µ£‚Çô, ùêù‚Çú·µ£‚Çô = shuffle_dataset(ùêó‚Çú·µ£‚Çô, ùêù‚Çú·µ£‚Çô)
        end
        # test!
        acc‚Çú‚Çõ‚Çú[n·µ£] = test(ùêó‚Çú‚Çõ‚Çú, ùêù‚Çú‚Çõ‚Çú, ùê∞)
        
        # make plots!
        if n·µ£ == 1
            all_ùê∞‚Çí‚Çö‚Çú[:,i] = ùê∞ # save the optimum value reached during the 1th realization for setosa, versicolor, and virginica
            # if all attributes was taken into account, compute the accuracyxepochs for all classes
            if length(ùê∞) != 3
                local p = plot(acc‚Çú·µ£‚Çô, label="", xlabel=L"Epochs", ylabel="Accuracy", linewidth=2, title="Training accuracy for $(desired_label) class by epochs")
                display(p)
                savefig(p, "trab1 (single-unit perceptron)/figs/accuracy-by-epochs-for-$(desired_label).png")
                # for the setosa class, compute the confusion matrix
                if desired_label == "setosa"
                    ùêÇ = zeros(2,2) # confusion matrix
                    ùê≤‚Çú‚Çõ‚Çú = test(ùêó‚Çú‚Çõ‚Çú, ùêù‚Çú‚Çõ‚Çú, ùê∞, true)
                    for n ‚àà 1:length(ùê≤‚Çú‚Çõ‚Çú)
                        # predicted x true label
                        ùêÇ[ùê≤‚Çú‚Çõ‚Çú[n]+1, ùêù‚Çú‚Çõ‚Çú[n]+1] += 1
                    end
                    h = heatmap(ùêÇ, xlabel="Predicted labels", ylabel="True labels", xticks=(1:2, ("setosa", "not setosa")), yticks=(1:2, ("setosa", "not setosa")), title="Confusion matrix for the setosa class")
                    savefig(h, "trab1 (single-unit perceptron)/figs/setosa-confusion-matrix.png")
                    display(h) # TODO: put the number onto each confusion square
                end
            end
            # decision surface
            if length(ùê∞) == 3 # plot the surface only if the learning procedure was taken with only two attributes, the petal length and petal width (equals to 3 because the bias)
                œÜ = u‚Çç‚Çô‚Çé -> u‚Çç‚Çô‚Çé‚â•0 ? 1 : 0 # activation function of the single-unit perceptron
                x‚ÇÉ_range = floor(minimum(ùêó[2,:])):.1:ceil(maximum(ùêó[2,:]))
                x‚ÇÑ_range = floor(minimum(ùêó[3,:])):.1:ceil(maximum(ùêó[3,:]))
                y(x‚ÇÉ, x‚ÇÑ) = œÜ(dot([-1, x‚ÇÉ, x‚ÇÑ], ùê∞))
                p = surface(x‚ÇÉ_range, x‚ÇÑ_range, y, camera=(60,40,0), xlabel = "petal length", ylabel = "petal width", zlabel="decision surface")

                # scatter plot for the petal length and petal length width for the setosa class
                # train and desired label 
                scatter!(ùêó‚Çú·µ£‚Çô[2,ùêù‚Çú·µ£‚Çô.==1], ùêó‚Çú·µ£‚Çô[3,ùêù‚Çú·µ£‚Çô.==1], ones(length(filter(x->x==1, ùêù‚Çú·µ£‚Çô))),
                        markershape = :hexagon,
                        markersize = 4,
                        markeralpha = 0.6,
                        markercolor = :green,
                        markerstrokewidth = 3,
                        markerstrokealpha = 0.2,
                        markerstrokecolor = :black,
                        xlabel = "petal\nlength",
                        ylabel = "petal width",
                        camera = (60,40,0),
                        label = "$(desired_label) train set")
                
                # test and desired label 
                scatter!(ùêó‚Çú‚Çõ‚Çú[2,ùêù‚Çú‚Çõ‚Çú.==1], ùêó‚Çú‚Çõ‚Çú[3,ùêù‚Çú‚Çõ‚Çú.==1], ones(length(filter(x->x==1, ùêù‚Çú‚Çõ‚Çú))),
                        markershape = :cross,
                        markersize = 4,
                        markeralpha = 0.6,
                        markercolor = :green,
                        markerstrokewidth = 3,
                        markerstrokealpha = 0.2,
                        markerstrokecolor = :black,
                        xlabel = "petal\nlength",
                        ylabel = "petal width",
                        camera = (60,40,0),
                        label = "$(desired_label) test set")

                # train and not desired label 
                scatter!(ùêó‚Çú·µ£‚Çô[2,ùêù‚Çú·µ£‚Çô.==0], ùêó‚Çú·µ£‚Çô[3,ùêù‚Çú·µ£‚Çô.==0], zeros(length(filter(x->x==0, ùêù‚Çú·µ£‚Çô))),
                        markershape = :hexagon,
                        markersize = 4,
                        markeralpha = 0.6,
                        markercolor = :red,
                        markerstrokewidth = 3,
                        markerstrokealpha = 0.2,
                        markerstrokecolor = :black,
                        xlabel = "petal\nlength",
                        ylabel = "petal width",
                        camera = (60,40,0),
                        label = "not $(desired_label) train set")

                # test and not desired label 
                scatter!(ùêó‚Çú‚Çõ‚Çú[2,ùêù‚Çú‚Çõ‚Çú.==0], ùêó‚Çú‚Çõ‚Çú[3,ùêù‚Çú‚Çõ‚Çú.==0], zeros(length(filter(x->x==0, ùêù‚Çú‚Çõ‚Çú))),
                        markershape = :cross,
                        markersize = 4,
                        markeralpha = 0.6,
                        markercolor = :red,
                        markerstrokewidth = 3,
                        markerstrokealpha = 0.2,
                        markerstrokecolor = :black,
                        xlabel = "petal\nlength",
                        ylabel = "petal width",
                        camera = (60,40,0),
                        label = "not $(desired_label) test set")
                
                title!("Decision surface for the class $(desired_label)")
                display(p)
                savefig(p,"trab1 (single-unit perceptron)/figs/decision-surface-for-$(desired_label).png")
            end
        end
    end
    # analyze the accuracy statistics of each independent realization
    local aÃÑcÃÑcÃÑ = Œ£(acc‚Çú‚Çõ‚Çú)/N·µ£ # Mean
    local ùîºacc¬≤ = Œ£(acc‚Çú‚Çõ‚Çú.^2)/N·µ£
    local œÉacc = sqrt.(ùîºacc¬≤ .- aÃÑcÃÑcÃÑ.^2) # standard deviation
    
    # save the performance
    all_aÃÑcÃÑcÃÑ[i] = aÃÑcÃÑcÃÑ
    all_œÉacc[i] = œÉacc
    println("Mean accuracy for $(desired_label): $(aÃÑcÃÑcÃÑ)")
    println("Standard deviation for $(desired_label): $(œÉacc)")
end