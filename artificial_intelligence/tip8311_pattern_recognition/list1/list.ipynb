{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4\n",
    "\n",
    "## Nearest centroid classifier\n",
    "\n",
    "The nearest centroid classifier (NCC) is a classification model that compares a new instance with the estimated mean (centroid) vector of each class. The vector is then labeled with the class whose mean vector is closest.\n",
    "\n",
    "Consider:\n",
    "1. A set of classes, $\\Omega = \\left\\{1, 2, \\cdots, C\\right\\}$, where $C$ is the number of classes.\n",
    "1. A training set, given by $\\left\\{\\mathbf{x}_n, \\omega_n\\right\\}_{n=1}^N$, where $N$ is the size of the training set, and $\\omega_n \\in \\Omega$ is the label for the $n$-th instance of the training set.\n",
    "\n",
    "the nearest centroid classifier can be described as follows:\n",
    "\n",
    "1. Training phase\n",
    "    1. Compute the estimated mean vector, given by: $$\\hat{\\mathbf{m}}_i = \\frac{1}{\\mid N_i\\mid} \\sum_{\\forall n \\in N_i} \\mathbf{x}_n ,$$ where $N_i$ is a set of training samples belonging to the class $i$, and $\\mid N_i\\mid$ is its cardinality.\n",
    "1. Test phase\n",
    "    1. For a new instance, $\\mathbf{x}_n$, where $n>N$, compute the Euclidean distance between the new vector and each estimated mean vector, $d(\\mathbf{x}_n, \\hat{\\mathbf{m}}_i)$.\n",
    "    1. Decide by the class $i^\\star$, where $$d(\\mathbf{x}_n, \\hat{\\mathbf{m}}_{i^\\star}) < d(\\mathbf{x}_n, \\hat{\\mathbf{m}}_i), \\forall i\\neq i^\\star \\text{ and } i,i^\\star \\in \\Omega$$\n",
    "\n",
    "Let us define the estimated mean vectors\n",
    "$$\\hat{\\mathbf{m}}_1 = \\begin{bmatrix} 51.69 & 12.82 & 43.54 & 38.86 \\end{bmatrix}^\\mathsf{T}$$\n",
    "$$\\hat{\\mathbf{m}}_2 = \\begin{bmatrix} 71.51 & 20.75 & 64.11 & 50.77 \\end{bmatrix}^\\mathsf{T}$$\n",
    "$$\\hat{\\mathbf{m}}_3 = \\begin{bmatrix} 47.64 & 17.40 & 35.46 & 30.24 \\end{bmatrix}^\\mathsf{T}$$\n",
    "and the new instance\n",
    "$$\\mathbf{x}_n = \\begin{bmatrix} 80.07 & 48.07 & 52.40 & 32.01 \\end{bmatrix}^\\mathsf{T}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The new vector is labeled to class 2, its Euclidean distance was 36.18, whereas the other ones were [46.62 47.77]\n"
     ]
    }
   ],
   "source": [
    "from numpy import array, delete, set_printoptions\n",
    "from numpy.linalg import norm\n",
    "\n",
    "x   = array([80.07, 48.07, 52.40, 32.01])\n",
    "m_1 = array([51.69, 12.82, 43.54, 38.86])\n",
    "m_2 = array([71.51, 20.75, 64.11, 50.77])\n",
    "m_3 = array([47.64, 17.40, 35.46, 30.24])\n",
    "\n",
    "# set float precision of numpy array\n",
    "set_printoptions(precision=2)\n",
    "\n",
    "# compute the Euclidean distances\n",
    "euclidean_dist = list(map(norm, (x-m_1, x-m_2, x-m_3)))\n",
    "# winning Euclidean distance\n",
    "min_euc_dist = min(euclidean_dist)\n",
    "# winning class\n",
    "winning_class = euclidean_dist.index(min_euc_dist) + 1\n",
    "# other Euclidean distances\n",
    "other_euc_dist = delete(euclidean_dist, winning_class-1)\n",
    "\n",
    "print(f\"The new vector is labeled to class {winning_class}, its Euclidean distance was {min_euc_dist:.2f}, whereas the other ones were {other_euc_dist}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 5\n",
    "\n",
    "## Maximum correlation coefficient classifier\n",
    "\n",
    "The maximum correlation classifier has almost the same behavior as the nearest centroid classifier, but it uses the normalized data's inner product (a similarity measurement) as the decision criterion. Therefore, the decision rule becomes\n",
    "\n",
    "$$\\left<\\bar{\\mathbf{x}}_n, \\bar{\\mathbf{m}}_{i^\\star} \\right> > \\left<\\bar{\\mathbf{x}}_n, \\bar{\\mathbf{m}}_{i}\\right> , \\forall i\\neq i^\\star \\text{ and } i,i^\\star \\in \\Omega,$$\n",
    "\n",
    "where $\\bar{\\mathbf{v}} = \\mathbf{v}/\\lVert \\mathbf{v} \\lVert$, being $\\lVert \\mathbf{v} \\lVert$ the norm of $\\mathbf{v}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The new vector is labeled to class 2, its inner product was 11707.77, whereas the other ones were [8280.48 7477.04]\n"
     ]
    }
   ],
   "source": [
    "from numpy import array, inner, set_printoptions\n",
    "\n",
    "x   = array([80.07, 48.07, 52.40, 32.01])\n",
    "m_1 = array([51.69, 12.82, 43.54, 38.86])\n",
    "m_2 = array([71.51, 20.75, 64.11, 50.77])\n",
    "m_3 = array([47.64, 17.40, 35.46, 30.24])\n",
    "\n",
    "# set float precision of numpy array\n",
    "set_printoptions(precision=2)\n",
    "\n",
    "# inner products\n",
    "inner_prods = list(map(inner, (x, x, x), (m_1, m_2, m_3)))\n",
    "# winning inner product\n",
    "max_inner_prod = max(inner_prods)\n",
    "# winning class\n",
    "winning_class = inner_prods.index(max_inner_prod) + 1\n",
    "# other inner products\n",
    "other_inner_prods = delete(inner_prods, winning_class-1)\n",
    "\n",
    "print(f\"The new vector is labeled to class {winning_class}, its inner product was {max_inner_prod:.2f}, whereas the other ones were {other_inner_prods}\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "58ebac444dea18954d74fc2ca5db6d52db6181844543c8d1ee860a791e0308fb"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
