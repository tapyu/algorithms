using FileIO, JLD2, Random, LinearAlgebra, Plots, LaTeXStrings
Î£=sum

## algorithm parameters and hyperparameters
Náµ£ = 20 # number of realizations
Nâ‚‘ = 100 # number of epochs
c = 3 # number of perceptrons (neurons) of the single layer
Î± = 0.001 # learning step
Ïƒâ‚“ = .1 # signal standard deviation
N = 150 # number of instances
Nâ‚ = 2 # number of attributes
Nâ‚œáµ£â‚™ = 80 # % percentage of instances for the train dataset
Nâ‚œâ‚›â‚œ = 20 # % percentage of instances for the test dataset

## generate dummy data
ğ—âš« = [Ïƒâ‚“*randn(50)'.+1.5; Ïƒâ‚“*randn(50)'.+1]
ğ—â–³ = [Ïƒâ‚“*randn(50)'.+1; Ïƒâ‚“*randn(50)'.+2]
ğ—â­ = [Ïƒâ‚“*randn(50)'.+2; Ïƒâ‚“*randn(50)'.+2]

ğ— = [fill(-1,N)'; [ğ—âš« ğ—â–³ ğ—â­]]
ğƒ = [repeat([1,0,0],1,50) repeat([0,1,0],1,50) repeat([0,0,1],1,50)]

## useful functions
function shuffle_dataset(ğ—, ğƒ)
    shuffle_indices = Random.shuffle(1:size(ğ—,2))
    return ğ—[:, shuffle_indices], ğƒ[:, shuffle_indices]
end

function train(ğ—, ğƒ, ğ–â‚â‚™â‚, is_training_accuracy=true)
    Ï† = uâ‚â‚™â‚ -> uâ‚â‚™â‚>0 ? 1 : 0 # McCulloch and Pitts's activation function (step function)
    Nâ‚‘ = 0 # number of errors â¡ misclassifications
    for (ğ±â‚â‚™â‚, ğâ‚â‚™â‚) âˆˆ zip(eachcol(ğ—), eachcol(ğƒ))
        ğ›â‚â‚™â‚ = ğ–â‚â‚™â‚*ğ±â‚â‚™â‚# induced local field
        ğ²â‚â‚™â‚ = map(Ï†, ğ›â‚â‚™â‚) # for the training phase, you do not pass yâ‚â‚™â‚ to a harder decisor (the McCulloch and Pitts's activation function) (??? TODO)
        ğâ‚â‚™â‚ = ğâ‚â‚™â‚ - ğ²â‚â‚™â‚
        ğ–â‚â‚™â‚ += Î±*ğâ‚â‚™â‚*ğ±â‚â‚™â‚'

        # this part is optional: only if it is interested in seeing the accuracy evolution of the training dataset throughout the epochs
        i = findfirst(x->x==maximum(ğ›â‚â‚™â‚), ğ›â‚â‚™â‚)
        Nâ‚‘ = ğâ‚â‚™â‚[i]==1 ? Nâ‚‘ : Nâ‚‘+1
    end
    if is_training_accuracy
        accuracy = (size(ğƒ,2)-Nâ‚‘)/size(ğƒ,2)
        return ğ–â‚â‚™â‚, accuracy
    else
        return  ğ–â‚â‚™â‚
    end
end

function test(ğ—, ğƒ, ğ–â‚â‚™â‚)
    Nâ‚‘ = 0 # number of errors â¡ misclassifications
    for (ğ±â‚â‚™â‚, ğâ‚â‚™â‚) âˆˆ zip(eachcol(ğ—), eachcol(ğƒ))
        ğ›â‚â‚™â‚ = ğ–â‚â‚™â‚*ğ±â‚â‚™â‚# induced local field
        # yâ‚â‚™â‚ = map(Ï†, ğ›â‚â‚™â‚) # theoretically, you need to pass ğ›â‚â‚™â‚ through the activation function, but, in order to solve ambiguous instances (see Ajalmar's handwritings), we pick the class with the highest activation function input
        i = findfirst(x->x==maximum(ğ›â‚â‚™â‚), ğ›â‚â‚™â‚) # predicted value â†’ choose the highest activation function input as the selected class
        Nâ‚‘ = ğâ‚â‚™â‚[i]==1 ? Nâ‚‘ : Nâ‚‘+1
    end
    accuracy = (size(ğƒ,2)-Nâ‚‘)/size(ğƒ,2)
    return accuracy
end

## init
accâ‚œâ‚›â‚œ = fill(NaN, Náµ£) # vector of accuracies for test dataset
for náµ£ âˆˆ 1:Náµ£
    # initialize!
    ğ–â‚â‚™â‚ = rand(c, Nâ‚+1) # [ğ°â‚áµ€; ğ°â‚‚áµ€; ...; ğ°áµ€_c]
    accâ‚œáµ£â‚™ = fill(NaN, Nâ‚‘) # vector of accuracies for train dataset (to see its evolution during training phase)

    # prepare the data!
    global ğ—, ğƒ = shuffle_dataset(ğ—, ğƒ)
    # hould-out
    global ğ—â‚œáµ£â‚™ = ğ—[:,1:(N*Nâ‚œáµ£â‚™)Ã·100]
    global ğƒâ‚œáµ£â‚™ = ğƒ[:,1:(N*Nâ‚œáµ£â‚™)Ã·100]
    global ğ—â‚œâ‚›â‚œ = ğ—[:,size(ğƒâ‚œáµ£â‚™, 2)+1:end]
    global ğƒâ‚œâ‚›â‚œ = ğƒ[:,size(ğƒâ‚œáµ£â‚™, 2)+1:end]

    # train!
    for nâ‚‘ âˆˆ 1:Nâ‚‘ # for each epoch
        ğ–â‚â‚™â‚, accâ‚œáµ£â‚™[nâ‚‘] = train(ğ—â‚œáµ£â‚™, ğƒâ‚œáµ£â‚™, ğ–â‚â‚™â‚)
        ğ—â‚œáµ£â‚™, ğƒâ‚œáµ£â‚™ = shuffle_dataset(ğ—â‚œáµ£â‚™, ğƒâ‚œáµ£â‚™)
    end
    # test!
    global accâ‚œâ‚›â‚œ[náµ£] = test(ğ—â‚œâ‚›â‚œ, ğƒâ‚œâ‚›â‚œ, ğ–â‚â‚™â‚) # accuracy for this realization
    
    # make plots!
    if náµ£==1
        # training dataset accuracy evolution by epochs for the 1th realization
        local fig = plot(accâ‚œáµ£â‚™, ylims=(0,1), xlabel="Epochs", ylabel="Accuracy", linewidth=2)
        savefig(fig, "trab3 (single layer perceptron)/figs/dummy data - training dataset accuracy evolution.png")

        # plot heatmap for the 1th realization
        local xâ‚_range = floor(minimum(ğ—[2,:])):.1:ceil(maximum(ğ—[2,:]))
        local xâ‚‚_range = floor(minimum(ğ—[3,:])):.1:ceil(maximum(ğ—[3,:]))
        local y(xâ‚, xâ‚‚) = findfirst(a -> a==maximum(ğ–â‚â‚™â‚*[-1, xâ‚, xâ‚‚]), ğ–â‚â‚™â‚*[-1, xâ‚, xâ‚‚]) # predict

        fig = contour(xâ‚_range, xâ‚‚_range, y, xlabel = L"x_1", ylabel = L"x_2", fill=true, levels=2)
        # train circe label
        scatter!(ğ—â‚œáµ£â‚™[2,ğƒâ‚œáµ£â‚™[1,:].==1], ğ—â‚œáµ£â‚™[3,ğƒâ‚œáµ£â‚™[1,:].==1], markershape = :hexagon, markersize = 8, markeralpha = 0.6, markercolor = :white, markerstrokewidth = 3, markerstrokealpha = 0.2, markerstrokecolor = :black, label = "circe class [train]")
            
        # test circle label
        scatter!(ğ—â‚œâ‚›â‚œ[2,ğƒâ‚œâ‚›â‚œ[1,:].==1], ğ—â‚œâ‚›â‚œ[3,ğƒâ‚œâ‚›â‚œ[1,:].==1], markershape = :dtriangle, markersize = 8, markeralpha = 0.6, markercolor = :white, markerstrokewidth = 3, markerstrokealpha = 0.2, markerstrokecolor = :black, label = "circle class [test]")

        # train triangle label
        scatter!(ğ—â‚œáµ£â‚™[2,ğƒâ‚œáµ£â‚™[2,:].==1], ğ—â‚œáµ£â‚™[3,ğƒâ‚œáµ£â‚™[2,:].==1], markershape = :hexagon, markersize = 8, markeralpha = 0.6, markercolor = :cyan, markerstrokewidth = 3, markerstrokealpha = 0.2, markerstrokecolor = :black, label = "triangle class [train]")

        # test triangle label
        scatter!(ğ—â‚œâ‚›â‚œ[2,ğƒâ‚œâ‚›â‚œ[2,:].==1], ğ—â‚œâ‚›â‚œ[3,ğƒâ‚œâ‚›â‚œ[2,:].==1], markershape = :dtriangle, markersize = 8, markeralpha = 0.6, markercolor = :cyan, markerstrokewidth = 3, markerstrokealpha = 0.2, markerstrokecolor = :black, label = "triangle class [test]")

        # train star label
        scatter!(ğ—â‚œáµ£â‚™[2,ğƒâ‚œáµ£â‚™[3,:].==1], ğ—â‚œáµ£â‚™[3,ğƒâ‚œáµ£â‚™[3,:].==1], markershape = :hexagon, markersize = 8, markeralpha = 0.6, markercolor = :green, markerstrokewidth = 3, markerstrokealpha = 0.2, markerstrokecolor = :black, label = "star class [train]")

        # test star label
        scatter!(ğ—â‚œâ‚›â‚œ[2,ğƒâ‚œâ‚›â‚œ[3,:].==1], ğ—â‚œâ‚›â‚œ[3,ğƒâ‚œâ‚›â‚œ[3,:].==1], markershape = :dtriangle, markersize = 8, markeralpha = 0.6, markercolor = :green, markerstrokewidth = 3, markerstrokealpha = 0.2, markerstrokecolor = :black, label = "star class [test]")

        title!("heatmap")
        savefig(fig, "trab3 (single layer perceptron)/figs/dummy data - heatmap.png")
    end
end

# analyze the accuracy statistics of each independent realization
aÌ„cÌ„cÌ„ = Î£(accâ‚œâ‚›â‚œ)/Náµ£ # Mean
ğ”¼accÂ² = Î£(accâ‚œâ‚›â‚œ.^2)/Náµ£
Ïƒacc = sqrt.(ğ”¼accÂ² .- aÌ„cÌ„cÌ„.^2) # standard deviation

println("Mean: $(aÌ„cÌ„cÌ„)")
println("Standard deviation: $(Ïƒacc)")