using LinearAlgebra, Plots, LaTeXStrings, DSP

Nâ‚› = 1000 # number of samples
N = 13 # 13 tapped delay plus the bias
ğ± = 2âˆš(3)rand(Nâ‚›).-âˆš(3) # ~ U(-âˆš(3), âˆš(3)) -> Ïƒâ‚“Â² = 1
Î¼â‚˜â‚â‚“ = 1/N
ğ‘ = I(N) # correlation matrix of x(n) -> is I since it is a white process
Ïƒâ‚™Â² = 1e-3 # measurement variance
ğ”¼eÂ²â‚˜áµ¢â‚™ = Ïƒâ‚™Â² # minimum MSE (only achievable by the steepest descent method, using the deterministic gradient)

# system output
ğÊ¼ = [0; rand(Nâ‚›-1)] # initial stage
for n âˆˆ N:Nâ‚›
    ğÊ¼[n] = ğÊ¼[n-1] + ğ±[n] - ğ±[n-12]
end

# reference signal (system output + noise)
ğ§ = âˆš(Ïƒâ‚™Â²)randn(Nâ‚›) # ~ N(0, Ïƒâ‚™Â²)
ğ = ğÊ¼ + ğ§

plots_lms = Array{Plots.Plot{Plots.GRBackend}, 1}(undef,4) # or Vector{Plots.GRBackend}(undef,4)
plots_mse = Array{Plots.Plot{Plots.GRBackend}, 1}(undef,4) # or Vector{Plots.GRBackend}(undef,4)
for (j, i) âˆˆ enumerate((1, 2, 10, 50))
    Î¼ = Î¼â‚˜â‚â‚“/i # step learning
    # the LMS algorithm
    global ğ°â‚â‚™â‚ = rand(N) # initial coefficient vector
    ğ”¼eÂ² = zeros(Nâ‚›) # MSE (mean-squared error) signal
    ğ² = [fill(NaN, N); rand(Nâ‚›-N)] # adaptive filter output
    for n âˆˆ N:Nâ‚›
        ğ±â‚â‚™â‚ = ğ±[n:-1:n-12] # input signal
        ğ²[n] = ğ±â‚â‚™â‚ â‹… ğ°â‚â‚™â‚ # adaptive filter output
        eâ‚â‚™â‚ = ğ[n] - ğ²[n] # signal error
        ğ”¼eÂ²[n] = ((n-N)*ğ”¼eÂ²[n-1] + eâ‚â‚™â‚^2)/(n-N+1) # estimate the the MSE recursively
        ğ°â‚â‚™â‚ += 2Î¼*eâ‚â‚™â‚*ğ±â‚â‚™â‚
    end
    plots_lms[j] = plot([ğ ğ²], label=[L"d(n)" L"y(n)"*" for "*L"\mu=\mu_{max}"*(i!=1 ? "/$(i)" : "")], xlabel="n", legend=:topleft)
    plots_mse[j] = plot(ğ”¼eÂ², label=L"e^2(n)"*" for "*L"\mu=\mu_{max}"*(i!=1 ? "/$(i)" : ""), xlabel="n", legend=:bottomright)

    ğ”¼eÂ²â‚‘â‚“c = ğ”¼eÂ²[end] - ğ”¼eÂ²â‚˜áµ¢â‚™

    # println("Excess MSE = $(ğ”¼eÂ²â‚‘â‚“c) for Î¼ = Î¼â‚˜â‚â‚“/$(i) (practical result)")
    # println("Excess MSE = $(Î¼*Ïƒâ‚™Â²*tr(ğ‘)/(1 - Î¼*tr(ğ‘))) for Î¼ = Î¼â‚˜â‚â‚“/$(i) (theoretical result)")

    println("Misadjustment M = $(ğ”¼eÂ²â‚‘â‚“c/ğ”¼eÂ²â‚˜áµ¢â‚™) for Î¼ = Î¼â‚˜â‚â‚“/$(i) (practical result)")
    println("Misadjustment M = $(Î¼*tr(ğ‘)/(1 - Î¼*tr(ğ‘))) for Î¼ = Î¼â‚˜â‚â‚“/$(i) (theoretical result)")
end

# save LMS fig convergence
fig = plot(plots_lms..., layout=(4,1), size=(1200,800), title=["System identification output for differents learning steps" "" "" ""]) # plots_lms... -> dereferencing
savefig(fig, "list3/figs/q5_lms_algorithm.png")

# save MSE
fig = plot(plots_mse..., layout=(4,1), size=(1200,800)) # plots_ems... -> dereferencing
savefig(fig, "list3/figs/q5_mse_algorithm.png")

H = DSP.PolynomialRatio([1; fill(0,11); -1], [1, -1]) # transfer function of H(â„¯^(jÏ‰)) vs. HÌ‚(â„¯^(jÏ‰))
Hâ‚wâ‚, w = DSP.freqresp(H)
fig = plot(w, abs.(Hâ‚wâ‚), label=L"\mid H(e^{jw})\mid", linewidth=2)
HÌ‚ = DSP.PolynomialRatio(ğ°â‚â‚™â‚, [1])
HÌ‚â‚wâ‚, w = DSP.freqresp(HÌ‚)
plot!(w, abs.(HÌ‚â‚wâ‚), xlabel="Digital frequency "*L"w"*" (radians/sample)", label=L"\mid\hat{H}(e^{jw})\mid", xticks = ([0, Ï€/2, Ï€], ["0", "Ï€/2", "Ï€"]), linewidth=2)
savefig(fig, "list3/figs/transfer_function.png")