using Random, Plots, LaTeXStrings, LinearAlgebra
Î£=sum

## algorithm hyperparameters
N = 50
Nâ‚œáµ£â‚™ = 80 # % percentage of instances for the train dataset
Nâ‚œâ‚›â‚œ = 20 # % percentage of instances for the test dataset
Nâ‚â‚ = 1 # number of number of attributes for the first function (without bias)
Nâ‚â‚‚ = 2 # number of number of attributes for the first function (without bias)
Náµ£ = 20 # number of realizations
Nâ‚‘ = 100 # number of epochs
Î± = 0.002 # learning step
Î¼â‚™, ÏƒÂ²â‚™ = 0, 10 # Gaussian parameters

## useful functions
function shuffle_dataset(ğ—, ğ)
    shuffle_indices = Random.shuffle(1:size(ğ—,2))
    return ğ—[:, shuffle_indices], ğ[shuffle_indices]
end

function train(ğ—â‚œáµ£â‚™, ğâ‚œáµ£â‚™, ğ°)
    ğâ‚œáµ£â‚™ = rand(length(ğâ‚œáµ£â‚™)) # vector of errors
    for (n, (ğ±â‚â‚™â‚, dâ‚â‚™â‚)) âˆˆ enumerate(zip(eachcol(ğ—â‚œáµ£â‚™), ğâ‚œáµ£â‚™))
        Î¼â‚™ = dot(ğ±â‚â‚™â‚,ğ°) # inner product
        yâ‚â‚™â‚ = Î¼â‚™ # ADALINE's activation function
        eâ‚â‚™â‚ = dâ‚â‚™â‚ - yâ‚â‚™â‚
        ğ° += Î±*eâ‚â‚™â‚*ğ±â‚â‚™â‚
        ğâ‚œáµ£â‚™[n] = eâ‚â‚™â‚
    end
    ğ”¼ğâ‚œáµ£â‚™Â² = Î£(ğâ‚œáµ£â‚™.^2)/length(ğâ‚œáµ£â‚™)  # MSE (Mean squared error), that is, the the estimative of second moment of the error signal for this epoch
    return ğ°, ğ”¼ğâ‚œáµ£â‚™Â²
end

function test(ğ—â‚œâ‚›â‚œ, ğâ‚œâ‚›â‚œ, ğ°)
    ğâ‚œâ‚›â‚œ = rand(length(ğâ‚œâ‚›â‚œ)) # vector of errors
    for (n, (ğ±â‚â‚™â‚, dâ‚â‚™â‚)) âˆˆ enumerate(zip(eachcol(ğ—â‚œâ‚›â‚œ), ğâ‚œâ‚›â‚œ))
        Î¼â‚™ = ğ±â‚â‚™â‚â‹…ğ° # inner product
        yâ‚â‚™â‚ = Î¼â‚™ # ADALINE's activation function
        ğâ‚œâ‚›â‚œ[n] = dâ‚â‚™â‚ - yâ‚â‚™â‚
    end
    ğ”¼ğâ‚œâ‚›â‚œÂ² = Î£(ğâ‚œâ‚›â‚œ.^2)/length(ğâ‚œâ‚›â‚œ) # MSE (Mean squared error), that is, the the estimative of second moment of the error signal for this epoch
    return ğ”¼ğâ‚œâ‚›â‚œÂ² # MSE
end

## generate dummy data
fâ‚(x) = 5x .+ 8 # two attributes (Nâ‚ = 2), they are a = 5, b = 8
fâ‚‚(xâ‚, xâ‚‚) =5xâ‚ .+ 3xâ‚‚ .+ 6 # three attributes (Nâ‚ = 3), they are a = 2, b = 3, c = 6

ğ§ = âˆšÏƒÂ²â‚™*randn(N) .+ Î¼â‚™ # ~ N(Î¼â‚™, ÏƒÂ²â‚™)
ğâ‚ = fâ‚(range(-10,10,N)) + ğ§ # dummy desired dataset for function 1
ğâ‚‚ = fâ‚‚(range(-10,10,N), range(-10,10,N)) + ğ§ # dummy desired dataset for function 2
ğ—â‚ = [fill(-1,N)'; range(-10,10,N)'] # dummy input dataset
ğ—â‚‚ = [fill(-1,N)'; range(-10,10,N)'; range(-10,10,N)'] # dummy input dataset

## init
ğ°â‚â‚’â‚šâ‚œ, ğ°â‚‚â‚’â‚šâ‚œ = rand(Nâ‚â‚+1), rand(Nâ‚â‚‚+1) # two attributes: bias + xâ‚â‚™â‚

MSEâ‚â‚œâ‚›â‚œ = rand(Náµ£)
MSEâ‚‚â‚œâ‚›â‚œ = rand(Náµ£)
for náµ£ âˆˆ 1:Náµ£
    # initialize!
    ğ°â‚, ğ°â‚‚ = rand(Nâ‚â‚+1), rand(Nâ‚â‚‚+1) # two attributes bias + xâ‚â‚™â‚
    MSEâ‚â‚œáµ£â‚™ = zeros(Nâ‚‘) # vector that stores the error train dataset for each epoch (to see its evolution)
    MESâ‚‚â‚œáµ£â‚™ = zeros(Nâ‚‘)

    # prepare the data!
    global ğ—â‚ # ?
    global ğâ‚ # ?
    global ğ—â‚‚ # ?
    global ğâ‚‚ # ?
    ğ—â‚, ğâ‚ = shuffle_dataset(ğ—â‚, ğâ‚)
    ğ—â‚‚, ğâ‚‚ = shuffle_dataset(ğ—â‚‚, ğâ‚‚)
    # hould-out
    global ğ—â‚â‚œáµ£â‚™ = ğ—â‚[:,1:(N*Nâ‚œáµ£â‚™)Ã·100] # for (ğ—â‚, ğâ‚)
    global ğâ‚â‚œáµ£â‚™ = ğâ‚[1:(N*Nâ‚œáµ£â‚™)Ã·100]
    global ğ—â‚â‚œâ‚›â‚œ = ğ—â‚[:,length(ğâ‚â‚œáµ£â‚™)+1:end]
    global ğâ‚â‚œâ‚›â‚œ = ğâ‚[length(ğâ‚â‚œáµ£â‚™)+1:end]

    global ğ—â‚‚â‚œáµ£â‚™ = ğ—â‚‚[:,1:(N*Nâ‚œáµ£â‚™)Ã·100] # for (ğ—â‚‚, ğâ‚‚)
    global ğâ‚‚â‚œáµ£â‚™ = ğâ‚‚[1:(N*Nâ‚œáµ£â‚™)Ã·100]
    global ğ—â‚‚â‚œâ‚›â‚œ = ğ—â‚‚[:,length(ğâ‚‚â‚œáµ£â‚™)+1:end]
    global ğâ‚‚â‚œâ‚›â‚œ = ğâ‚‚[length(ğâ‚‚â‚œáµ£â‚™)+1:end]

    # train!
    for nâ‚‘ âˆˆ 1:Nâ‚‘
        ğ°â‚, MSEâ‚â‚œáµ£â‚™[nâ‚‘] = train(ğ—â‚â‚œáµ£â‚™, ğâ‚â‚œáµ£â‚™, ğ°â‚)
        ğ°â‚‚, MESâ‚‚â‚œáµ£â‚™[nâ‚‘] = train(ğ—â‚‚â‚œáµ£â‚™, ğâ‚‚â‚œáµ£â‚™, ğ°â‚‚)
        ğ—â‚â‚œáµ£â‚™, ğâ‚â‚œáµ£â‚™ = shuffle_dataset(ğ—â‚â‚œáµ£â‚™, ğâ‚â‚œáµ£â‚™)
        ğ—â‚‚â‚œáµ£â‚™, ğâ‚‚â‚œáµ£â‚™ = shuffle_dataset(ğ—â‚‚â‚œáµ£â‚™, ğâ‚‚â‚œáµ£â‚™)
    end
    # test!
    MSEâ‚â‚œâ‚›â‚œ[náµ£] = test(ğ—â‚â‚œâ‚›â‚œ, ğâ‚â‚œâ‚›â‚œ, ğ°â‚)
    MSEâ‚‚â‚œâ‚›â‚œ[náµ£] = test(ğ—â‚‚â‚œâ‚›â‚œ, ğâ‚‚â‚œâ‚›â‚œ, ğ°â‚‚)

    # make plots!
    if náµ£ == 1
        global ğ°â‚â‚’â‚šâ‚œ = ğ°â‚ # save the optimum value reached during the 1th realization fâ‚(â‹…)
        global ğ°â‚‚â‚’â‚šâ‚œ = ğ°â‚‚ # save the optimum value reached during the 1th realization fâ‚‚(â‹…)

        local fig = plot(MSEâ‚â‚œáµ£â‚™, label="", xlabel=L"Epochs", ylabel=L"MSE_{1}", linewidth=2, title="Training MSE for"*L"f_1(x_n)=ax+b"*" class by epochs\n(1th realization)", ylims=(0, 5))
        display(fig)
        savefig(fig, "trab2 (ADALINE)/figs/MES-by-epochs-for-f1.png")
        fig = plot(10*log10.(MESâ‚‚â‚œáµ£â‚™), label="", xlabel=L"Epochs", ylabel=L"MSE_{2}"*" in (dB)", linewidth=2, title="Training MSE for "*L"f_2(x_1,x_2)=ax_1(n)+bx_2(n)+c"*" class by epochs\n(1th realization)", ylims=(0, 40))
        savefig(fig, "trab2 (ADALINE)/figs/MES-by-epochs-for-f2.png")
        display(fig)
    end
end

RMSEâ‚â‚œâ‚›â‚œ = sqrt.(MSEâ‚â‚œâ‚›â‚œ)
MÌ„SÌ„EÌ„â‚, RÌ„MÌ„SÌ„EÌ„â‚ = Î£(MSEâ‚â‚œâ‚›â‚œ)/length(MSEâ‚â‚œâ‚›â‚œ), Î£(RMSEâ‚â‚œâ‚›â‚œ)/length(RMSEâ‚â‚œâ‚›â‚œ) # mean of the MSE and RMSE of the all realizations
ğ”¼MSEâ‚Â², ğ”¼RMSEâ‚Â² = Î£(MSEâ‚â‚œâ‚›â‚œ.^2)/length(MSEâ‚â‚œâ‚›â‚œ), Î£(RMSEâ‚â‚œâ‚›â‚œ.^2)/length(RMSEâ‚â‚œâ‚›â‚œ) # second moment of the MSE and RMSE of the all realizations
Ïƒâ‚â‚˜â‚›â‚‘, Ïƒâ‚áµ£â‚˜â‚›â‚‘ = âˆš(ğ”¼MSEâ‚Â² - MÌ„SÌ„EÌ„â‚^2), âˆš(ğ”¼RMSEâ‚Â² - RÌ„MÌ„SÌ„EÌ„â‚^2) # standard deviation of the MSE of the all realizations

RMSEâ‚‚â‚œâ‚›â‚œ = sqrt.(MSEâ‚‚â‚œâ‚›â‚œ)
MÌ„SÌ„EÌ„â‚‚, RÌ„MÌ„SÌ„EÌ„â‚‚ = Î£(MSEâ‚‚â‚œâ‚›â‚œ)/length(MSEâ‚‚â‚œâ‚›â‚œ), Î£(RMSEâ‚‚â‚œâ‚›â‚œ)/length(RMSEâ‚‚â‚œâ‚›â‚œ) # mean of the MSE and RMSE of the all realizations
ğ”¼MSEâ‚‚Â², ğ”¼RMSEâ‚‚Â² = Î£(MSEâ‚‚â‚œâ‚›â‚œ.^2)/length(MSEâ‚‚â‚œâ‚›â‚œ), Î£(RMSEâ‚‚â‚œâ‚›â‚œ.^2)/length(RMSEâ‚‚â‚œâ‚›â‚œ) # second moment of the MSE and RMSE of the all realizations
Ïƒâ‚‚â‚˜â‚›â‚‘, Ïƒâ‚‚áµ£â‚˜â‚›â‚‘ = âˆš(ğ”¼MSEâ‚‚Â² - MÌ„SÌ„EÌ„â‚‚^2), âˆš(ğ”¼RMSEâ‚‚Â² - RÌ„MÌ„SÌ„EÌ„â‚‚^2) # standard deviation of the MSE of the all realizations

println("MSE, RMSE mean for fâ‚(â‹…): $(MÌ„SÌ„EÌ„â‚), $(RÌ„MÌ„SÌ„EÌ„â‚)")
println("MSE, RMSE standard deviation for fâ‚(â‹…): $(Ïƒâ‚â‚˜â‚›â‚‘), $(Ïƒâ‚áµ£â‚˜â‚›â‚‘)")
println("MSE, RMSE mean for fâ‚‚(â‹…): $(MÌ„SÌ„EÌ„â‚‚), $(RÌ„MÌ„SÌ„EÌ„â‚‚)")
println("MSE, RMSE standard deviation for fâ‚‚(â‹…): $(Ïƒâ‚‚â‚˜â‚›â‚‘), $(Ïƒâ‚‚áµ£â‚˜â‚›â‚‘)")

## predict!
ğâ‚ = fâ‚(range(-10,10,N)) + ğ§ # dummy desired dataset for function 1
ğâ‚‚ = fâ‚‚(range(-10,10,N), range(-10,10,N)) + ğ§ # dummy desired dataset for function 2

ğ²â‚ = [fill(-1, N) range(-10,10,N)]*ğ°â‚â‚’â‚šâ‚œ
ğ²â‚‚ = [fill(-1, N) range(-10,10,N) range(-10,10,N)]*ğ°â‚‚â‚’â‚šâ‚œ

fig = plot(range(-10,10,N), [ğâ‚ ğ²â‚], label=["Input signal" "Predicted signal"], ylabel=L"f_1(x)", xlabel=L"x", linewidth=2, title="Predicted signal for"*L"f_1(x)")
display(fig)
savefig(fig, "trab2 (ADALINE)/figs/predict-f1.png")

fig = plot3d(range(-10,10,N), range(-10,10,N), ğâ‚‚, label="Input signal", linewidth=2, title="Predicted signal for "*L"f_2(x)", xlabel=L"x_1", ylabel=L"x_2", zlabel=L"f_2(x_1,x_2)")
plot3d!(range(-10,10,N), range(-10,10,N), ğ²â‚‚, label="Predicted signal", linewidth=2)
display(fig)
savefig(fig, "trab2 (ADALINE)/figs/predict-f2.png")