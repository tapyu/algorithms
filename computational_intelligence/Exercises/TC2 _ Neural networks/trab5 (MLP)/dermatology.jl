using FileIO, JLD2, Random, LinearAlgebra, Plots, LaTeXStrings, DataStructures
include("grid_search_cross_validation.jl")
Î£=sum
âŠ™ = .* # Hadamard product

# Attribute(feature) Information:
# 1: erythema                                  ### Clinical Attributes: (take values 0, 1, 2, 3, unless otherwise indicated)
# 2: scaling
# 3: definite borders
# 4: itching
# 5: koebner phenomenon
# 6: polygonal papules
# 7: follicular papules
# 8: oral mucosal involvement
# 9: knee and elbow involvement
# 10: scalp involvement
# 11: family history, (0 or 1)
# 34: Age (linear)
# 12: melanin incontinence                     ### Histopathological Attributes: (take values 0, 1, 2, 3)
# 13: eosinophils in the infiltrate
# 14: PNL infiltrate
# 15: fibrosis of the papillary dermis
# 16: exocytosis
# 17: acanthosis
# 18: hyperkeratosis
# 19: parakeratosis
# 20: clubbing of the rete ridges
# 21: elongation of the rete ridges
# 22: thinning of the suprapapillary epidermis
# 23: spongiform pustule
# 24: munro microabcess
# 25: focal hypergranulosis
# 26: disappearance of the granular layer
# 27: vacuolisation and damage of basal layer
# 28: spongiosis
# 29: saw-tooth appearance of retes
# 30: follicular horn plug
# 31: perifollicular parakeratosis
# 32: inflammatory monoluclear inflitrate
# 33: band-like infiltrate

# Class information
#        Class code:   Class:                  Number of instances:
#        1             psoriasis			           112
#        2             seboreic dermatitis             61
#        3             lichen planus                   72
#        4             pityriasis rosea                49
#        5             cronic dermatitis               52
#        6             pityriasis rubra pilaris        20

function one_hot_encoding(label)
    return 1:6 .== label
end

function shuffle_dataset(ğ—, ğƒ)
    shuffle_indices = Random.shuffle(1:size(ğ—,2))
    return ndims(ğƒ)==1 ? (ğ—[:, shuffle_indices], ğƒ[shuffle_indices]) : ğ—[:, shuffle_indices], ğƒ[:, shuffle_indices]
end

function train(ğ—, ğƒ, ğ”š, Ï†, Ï†Ê¼)
    L = length(ğ”š) # number of layers
    Nâ‚‘ = 0 # number of errors â¡ misclassifications
    for (ğ±â‚â‚™â‚, ğâ‚â‚™â‚) âˆˆ zip(eachcol(ğ—), eachcol(ğƒ)) # n-th instance
        # initialize the output and the vetor of gradients of each layer!
        ğ”¶â‚â‚™â‚ = OrderedDict([(l, rand(size(ğ–â½Ë¡â¾â‚â‚™â‚, 1))) for (l, ğ–â½Ë¡â¾â‚â‚™â‚) âˆˆ ğ”š])  # output of the l-th layer at the instant n
        ğ”¶Ê¼â‚â‚™â‚ = OrderedDict(ğ”¶â‚â‚™â‚) # diff of the output of the l-th layer at the instant n
        ğ”¡â‚â‚™â‚ = OrderedDict(ğ”¶â‚â‚™â‚) # all local gradients of all layers
        # forward phase!
        for (l, ğ–â½Ë¡â¾â‚â‚™â‚) âˆˆ ğ”š # l-th layer
            ğ¯â½Ë¡â¾â‚â‚™â‚ = l==1 ? ğ–â½Ë¡â¾â‚â‚™â‚*ğ±â‚â‚™â‚ : ğ–â½Ë¡â¾â‚â‚™â‚*[-1; ğ”¶â‚â‚™â‚[l-1]] # induced local field
            ğ”¶â‚â‚™â‚[l] = map(Ï†, ğ¯â½Ë¡â¾â‚â‚™â‚)
            ğ”¶Ê¼â‚â‚™â‚[l] = map(Ï†Ê¼, ğ”¶â‚â‚™â‚[l])
        end
        # backward phase!
        for l âˆˆ L:-1:1
            if l==L # output layer
                ğâ‚â‚™â‚ = ğâ‚â‚™â‚ - ğ”¶â‚â‚™â‚[L]
                i = findfirst(x->x==maximum(ğ”¶â‚â‚™â‚[L]), ğ”¶â‚â‚™â‚[L]) # predicted value â†’ choose the highest activation function output as the selected class
                Nâ‚‘ = ğâ‚â‚™â‚[i]==1 ? Nâ‚‘ : Nâ‚‘+1 # count error if it occurs
                ğ”¡â‚â‚™â‚[L] = ğ”¶Ê¼â‚â‚™â‚[L] âŠ™ ğâ‚â‚™â‚
            else # hidden layers
                ğ”¡â‚â‚™â‚[l] = ğ”¶Ê¼â‚â‚™â‚[l] âŠ™ ğ”š[l+1][:,2:end]'*ğ”¡â‚â‚™â‚[l+1] # vector of local gradients of the l-th layer
            end
            ğ”š[l] = l==1 ? ğ”š[l]+Î·*ğ”¡â‚â‚™â‚[l]*ğ±â‚â‚™â‚' : ğ”š[l]+Î·*ğ”¡â‚â‚™â‚[l]*[-1; ğ”¶â‚â‚™â‚[l-1]]' # learning equation
        end
    end
    return ğ”š, (size(ğƒ,2)-Nâ‚‘)/size(ğƒ,2) # trained neural network synaptic weights and its accuracy
end

function test(ğ—, ğƒ, ğ”š, Ï†, is_confusion_matrix=false)
    L = length(ğ”š) # number of layers
    Nâ‚‘ = 0 # number of errors â¡ misclassification
    ğ˜ = rand(size(ğƒ)...)
    for (n, (ğ±â‚â‚™â‚, ğâ‚â‚™â‚)) âˆˆ enumerate(zip(eachcol(ğ—), eachcol(ğƒ))) # n-th instance
        # initialize the output and the vetor of gradients of each layer!
        ğ”¶â‚â‚™â‚ = OrderedDict([(l, rand(size(ğ–â½Ë¡â¾â‚â‚™â‚, 1))) for (l, ğ–â½Ë¡â¾â‚â‚™â‚) âˆˆ ğ”š])  # output of the l-th layer at the instant n
        # forward phase!
        for (l, ğ–â½Ë¡â¾â‚â‚™â‚) âˆˆ ğ”š # l-th layer
            ğ¯â½Ë¡â¾â‚â‚™â‚ = l==1 ? ğ–â½Ë¡â¾â‚â‚™â‚*ğ±â‚â‚™â‚ : ğ–â½Ë¡â¾â‚â‚™â‚*[-1; ğ”¶â‚â‚™â‚[l-1]] # induced local field
            ğ”¶â‚â‚™â‚[l] = map(Ï†, ğ¯â½Ë¡â¾â‚â‚™â‚)
            if l==L # output layer
                i = findfirst(x->x==maximum(ğ”¶â‚â‚™â‚[L]), ğ”¶â‚â‚™â‚[L]) # predicted value â†’ choose the highest activation function output as the selected class
                ğ˜[:,n] = 1:length(ğâ‚â‚™â‚).==i
                Nâ‚‘ = ğâ‚â‚™â‚[i]==1 ? Nâ‚‘ : Nâ‚‘+1 # count error if it occurs
            end
        end
    end
    if is_confusion_matrix
        return Int.(ğ˜)
    else
        return (size(ğƒ,2)-Nâ‚‘)/size(ğƒ,2)
    end
end

## algorithm parameters and hyperparameters
K = 6 # number of classes (psoriasis, seboreic dermatitis, lichen planus, pityriasis rosea, cronic dermatitis, pityriasis rubra pilaris)
N = 358 # number of instances
Nâ‚œáµ£â‚™ = 80 # % percentage of instances for the train dataset
Nâ‚œâ‚›â‚œ = 20 # % percentage of instances for the test dataset
Nâ‚ = 34 # number of number of attributes (sepal length, sepal width, petal length, petal width)
Náµ£ = 20 # number of realizations
Nâ‚‘ = 100 # number of epochs
mâ‚‚ = K # number of perceptrons (neurons) of the output layer = output vector size = number of classes
Î· = 0.1 # learning step

## load dataset
ğ—, labels = FileIO.load("../Datasets/Dermatology [uci]/dermatology.jld2", "ğ—", "ğ") # ğ— â¡ [attributes X instances]
ğƒ = rand(K,0)
for label âˆˆ labels
    global ğƒ = [ğƒ one_hot_encoding(label)]
end
## Standardize dataset (Preprocessing)
ğ›â‚“ = Î£(ğ—, dims=2)/N # mean vector
ğ”¼Î¼Â² = Î£(ğ—.^2, dims=2)/N # vector of the second moment of ğ—
ÏƒÎ¼ = sqrt.(ğ”¼Î¼Â² - ğ›â‚“.^2) # vector of the standard deviation
ğ— = (ğ— .- ğ›â‚“)./ÏƒÎ¼ # zero mean and unit variance
ğ— = [fill(-1, size(ğ—,2))'; ğ—] # add the -1 input (bias)

## init
ğ›â‚œâ‚›â‚œ = fill(NaN, Náµ£) # vector of accuracies for test dataset
for náµ£ âˆˆ 1:Náµ£
    # prepare the data!
    global ğ—, ğƒ = shuffle_dataset(ğ—, ğƒ)
    # hould-out
    ğ—â‚œáµ£â‚™ = ğ—[:,1:(N*Nâ‚œáµ£â‚™)Ã·100-6]
    ğƒâ‚œáµ£â‚™ = ğƒ[:,1:(N*Nâ‚œáµ£â‚™)Ã·100-6]
    ğ—â‚œâ‚›â‚œ = ğ—[:,size(ğƒâ‚œáµ£â‚™, 2)+1-6:end]
    ğƒâ‚œâ‚›â‚œ = ğƒ[:,size(ğƒâ‚œáµ£â‚™, 2)+1-6:end]
    # print("ğ—â‚œáµ£â‚™: $(size(ğ—â‚œáµ£â‚™))\nğ—â‚œâ‚›â‚œ: $(size(ğ—â‚œâ‚›â‚œ))")
    
    # grid search with k-fold cross validation!
    (mâ‚, (Ï†, Ï†Ê¼, a)) = grid_search_cross_validation(ğ—â‚œáµ£â‚™, ğƒâ‚œáµ£â‚™, 10, (33:38, ((vâ‚â‚™â‚ -> 1/(1+â„¯^(-vâ‚â‚™â‚)), yâ‚â‚™â‚ -> yâ‚â‚™â‚*(1-yâ‚â‚™â‚), 1), (vâ‚â‚™â‚ -> (1-â„¯^(-vâ‚â‚™â‚))/(1+â„¯^(-vâ‚â‚™â‚)), yâ‚â‚™â‚ -> .5(1-yâ‚â‚™â‚^2), 2))))
    # (mâ‚, (Ï†, Ï†Ê¼, a)) = (40, (vâ‚â‚™â‚ -> 1/(1+â„¯^(-vâ‚â‚™â‚)), yâ‚â‚™â‚ -> yâ‚â‚™â‚*(1-yâ‚â‚™â‚), 1))
    println("For the realization $(náµ£)")
    println("best mâ‚: $(mâ‚)")
    println("best Ï†: $(a==1 ? "logistic" : "Hyperbolic")")
    
    # initialize!
    ğ”š = OrderedDict(1 => rand(mâ‚, Nâ‚+1), 2 => rand(mâ‚‚, mâ‚+1)) # 1 => first (hidden) layer 2 => second (output) layer 
    ğ›â‚œáµ£â‚™ = fill(NaN, Nâ‚‘) # vector of accuracies for train dataset (to see its evolution during training phase)
    
    # train!
    for nâ‚‘ âˆˆ 1:Nâ‚‘ # for each epoch
        ğ”š, ğ›â‚œáµ£â‚™[nâ‚‘] = train(ğ—â‚œáµ£â‚™, ğƒâ‚œáµ£â‚™, ğ”š, Ï†, Ï†Ê¼)
        ğ—â‚œáµ£â‚™, ğƒâ‚œáµ£â‚™ = shuffle_dataset(ğ—â‚œáµ£â‚™, ğƒâ‚œáµ£â‚™)
    end
    # test!
    global ğ›â‚œâ‚›â‚œ[náµ£] = test(ğ—â‚œâ‚›â‚œ, ğƒâ‚œâ‚›â‚œ, ğ”š, Ï†) # accuracy for this realization
    
    # plot training dataset accuracy evolution
    local fig = plot(ğ›â‚œáµ£â‚™, ylims=(0,2), xlabel="Epochs", ylabel="Accuracy", linewidth=2)
    savefig(fig, "figs/dermatology - training dataset accuracy evolution for realization $(náµ£).png")

    # confusion matrix
    ğ‚ = zeros(2,2)
        ğ˜â‚œâ‚›â‚œ = test(ğ—â‚œâ‚›â‚œ, ğƒâ‚œâ‚›â‚œ, ğ”š, Ï†, true)
        for (l, label) âˆˆ enumerate(("psoriasis", "seboreic dermatitis", "lichen planus", "pityriasis rosea", "cronic dermatitis", "pityriasis rubra pilaris"))
            if !isfile("figs/dermatology-$(label)-confusion-matrix.png")
                for n âˆˆ 1:size(ğ˜â‚œâ‚›â‚œ, 2)
                    # predicted x true label
                    ğ‚[ğ˜â‚œâ‚›â‚œ[l, n]+1, Int(ğƒâ‚œâ‚›â‚œ[l, n])+1] += 1
                end
                fig = heatmap(ğ‚, xlabel="Predicted labels", ylabel="True labels", xticks=(1:2, ("not $(label)", "$(label)")), yticks=(1:2, ("not $(label)", "$(label)")), title="Confusion matrix for the label $(label)")
                savefig(fig, "figs/dermatology-$(label)-confusion-matrix.png") # TODO: put the number onto each confusion square
            end
        end
end


# analyze the accuracy statistics of each independent realization
Î¼Ì„â‚œâ‚›â‚œ = Î£(ğ›â‚œâ‚›â‚œ)/Náµ£ # mean
ğ”¼Î¼Â² = Î£(ğ›â‚œâ‚›â‚œ.^2)/Náµ£
ÏƒÎ¼ = sqrt(ğ”¼Î¼Â² - Î¼Ì„â‚œâ‚›â‚œ^2) # standard deviation

println("Mean: $(Î¼Ì„â‚œâ‚›â‚œ)")
println("Standard deviation: $(ÏƒÎ¼)")